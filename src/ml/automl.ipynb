{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:03.216416Z",
     "start_time": "2024-12-03T06:50:02.596832Z"
    }
   },
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:05.281615Z",
     "start_time": "2024-12-03T06:50:05.267084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('../../results/data/ml/train_data.csv', index_col=0)\n",
    "test_df = pd.read_csv('../../results/data/ml/test_data.csv', index_col=0)"
   ],
   "id": "fd38a7ce7e926cea",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:07:18.452056Z",
     "start_time": "2024-12-03T07:07:18.449355Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.group.value_counts()",
   "id": "8f75d9cdaacae215",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "HCC    225\n",
       "CHB    102\n",
       "LC     102\n",
       "HC      70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:50:06.946856Z",
     "start_time": "2024-12-03T06:50:06.943154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = TabularDataset(train_df)\n",
    "train_data[[\"group\"]] = train_data[[\"group\"]] == \"HCC\"\n",
    "test_data = TabularDataset(test_df)\n",
    "test_data[[\"group\"]] = test_data[[\"group\"]] == \"HCC\""
   ],
   "id": "d5a09f8b36da07a2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:52:09.639998Z",
     "start_time": "2024-12-03T06:50:08.490516Z"
    }
   },
   "cell_type": "code",
   "source": "predictor = TabularPredictor('group', eval_metric='roc_auc').fit(train_data, time_limit=120, presets='best_quality')",
   "id": "d6997de6b87f5718",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_065008\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.45 GB / 16.00 GB (34.1%)\n",
      "Disk Space Avail:   31.42 GB / 460.43 GB (6.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-12-03 14:50:09,551\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065008/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Running DyStack sub-fit ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Beginning AutoGluon training ... Time limit = 28s\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065008/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Train Data Rows:    443\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Train Data Columns: 82\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Label Column:       group\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Problem Type:       binary\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Preprocessing data ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Using Feature Generators to preprocess the data ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tAvailable Memory:                    5019.44 MB\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tTrain Data (Original)  Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tStage 1 Generators:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tStage 2 Generators:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tStage 3 Generators:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tStage 4 Generators:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tStage 5 Generators:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tUseless Original Features (Count: 1): ['H3N2F1']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('float', [])  : 77 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('int', [])    :  3 | ['AST', 'ALT', 'GGT']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('object', []) :  1 | ['child_pugh']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('category', [])  :  1 | ['child_pugh']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('float', [])     : 73 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('int', [])       :  3 | ['AST', 'ALT', 'GGT']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t\t('int', ['bool']) :  4 | ['H4N4F3S1', 'H4N6S1', 'H6N4F1S1', 'H6N6']\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s = Fit runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t81 features in original data used to generate 81 features in processed data.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tTrain Data (Processed) Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m User-specified model hyperparameters to be fit:\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m {\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m }\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 18.88s of the 28.33s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.8526\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.01s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 18.20s of the 27.64s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.8761\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 18.19s of the 27.64s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9042\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.64s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.01s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 16.03s of the 25.47s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.35%)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.8962\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.63s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.01s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 13.41s of the 22.85s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9023\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.52s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.03s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 12.84s of the 22.29s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9023\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.17s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.03s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 12.63s of the 22.07s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.68%)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9067\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t6.64s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.04s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4.59s of the 14.04s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.89\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.25s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.04s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4.29s of the 13.74s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.8862\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.2s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.03s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4.05s of the 13.50s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\u001B[36m(_ray_fit pid=97320)\u001B[0m No improvement since epoch 5: early stopping\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.8609\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t1.91s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.09s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.77s of the 10.21s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9003\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.74s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.02s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 28.33s of the 7.31s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tEnsemble Weights: {'KNeighborsDist_BAG_L1': 0.308, 'CatBoost_BAG_L1': 0.308, 'NeuralNetFastAI_BAG_L1': 0.231, 'ExtraTreesGini_BAG_L1': 0.077, 'XGBoost_BAG_L1': 0.077}\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9214\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.01s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 7.30s of the 7.28s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9191\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.52s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.02s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 4.93s of the 4.91s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.37%)\n",
      "\u001B[36m(_ray_fit pid=97323)\u001B[0m No improvement since epoch 8: early stopping\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.912\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.74s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.02s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 2.28s of the 2.26s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9036\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.32s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.04s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1.91s of the 1.89s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9031\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.31s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.04s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1.55s of the 1.53s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\u001B[36m(_ray_fit pid=97379)\u001B[0m \tRan out of time, early stopping on iteration 40.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.9142\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t1.36s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.03s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 28.33s of the -1.31s of remaining time.\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.524, 'ExtraTreesGini_BAG_L1': 0.19, 'KNeighborsDist_BAG_L1': 0.143, 'CatBoost_BAG_L2': 0.095, 'NeuralNetFastAI_BAG_L1': 0.048}\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.923\t = Validation score   (roc_auc)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.01s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m \t0.0s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m AutoGluon training complete, total runtime = 29.7s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 260.5 rows/s (56 batch size)\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065008/ds_sub_fit/sub_fit_ho\")\n",
      "\u001B[36m(_dystack pid=97274)\u001B[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestGini_BAG_L2       0.873548   0.903632     roc_auc        0.751998       0.273928  10.667958                 0.015153                0.038714           0.323838            2       True         15\n",
      "1       WeightedEnsemble_L2       0.869677   0.921399     roc_auc        0.531625       0.190953   9.544601                 0.000751                0.000173           0.012697            2       True         12\n",
      "2   RandomForestEntr_BAG_L2       0.865161   0.903138     roc_auc        0.750999       0.270973  10.654464                 0.014154                0.035759           0.310344            2       True         16\n",
      "3           LightGBM_BAG_L2       0.863226   0.911975     roc_auc        0.745586       0.254674  11.086105                 0.008741                0.019460           0.741985            2       True         14\n",
      "4         LightGBMXT_BAG_L2       0.861935   0.919136     roc_auc        0.745411       0.251556  10.864420                 0.008566                0.016342           0.520300            2       True         13\n",
      "5       WeightedEnsemble_L3       0.861935   0.923004     roc_auc        0.754800       0.278205  12.241738                 0.000712                0.000195           0.012720            3       True         18\n",
      "6   RandomForestEntr_BAG_L1       0.856774   0.902315     roc_auc        0.017940       0.032772   0.173785                 0.017940                0.032772           0.173785            1       True          6\n",
      "7           CatBoost_BAG_L1       0.852903   0.906749     roc_auc        0.313034       0.041424   6.637689                 0.313034                0.041424           6.637689            1       True          7\n",
      "8           CatBoost_BAG_L2       0.852903   0.914198     roc_auc        0.745522       0.261668  11.708718                 0.008677                0.026454           1.364598            2       True         17\n",
      "9           LightGBM_BAG_L1       0.847742   0.896173     roc_auc        0.018288       0.011461   0.630682                 0.018288                0.011461           0.630682            1       True          4\n",
      "10           XGBoost_BAG_L1       0.846452   0.900288     roc_auc        0.018794       0.019991   0.736922                 0.018794                0.019991           0.736922            1       True         11\n",
      "11  RandomForestGini_BAG_L1       0.843871   0.902274     roc_auc        0.020964       0.034029   0.522726                 0.020964                0.034029           0.522726            1       True          5\n",
      "12        LightGBMXT_BAG_L1       0.841290   0.904218     roc_auc        0.188031       0.011662   0.638431                 0.188031                0.011662           0.638431            1       True          3\n",
      "13    ExtraTreesEntr_BAG_L1       0.823226   0.886173     roc_auc        0.016694       0.033929   0.198000                 0.016694                0.033929           0.198000            1       True          9\n",
      "14    ExtraTreesGini_BAG_L1       0.813548   0.890031     roc_auc        0.018542       0.038150   0.245556                 0.018542                0.038150           0.245556            1       True          8\n",
      "15    KNeighborsDist_BAG_L1       0.798710   0.876091     roc_auc        0.002930       0.001296   0.002450                 0.002930                0.001296           0.002450            1       True          2\n",
      "16   NeuralNetFastAI_BAG_L1       0.796129   0.860926     roc_auc        0.177574       0.089919   1.909287                 0.177574                0.089919           1.909287            1       True         10\n",
      "17    KNeighborsUnif_BAG_L1       0.769032   0.852613     roc_auc        0.003377       0.013937   0.002806                 0.003377                0.013937           0.002806            1       True          1\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t33s\t = DyStack   runtime |\t87s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 87s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065008\"\n",
      "Train Data Rows:    499\n",
      "Train Data Columns: 82\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5947.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['H3N2F1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 77 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', [])    :  3 | ['AST', 'ALT', 'GGT']\n",
      "\t\t('object', []) :  1 | ['child_pugh']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['child_pugh']\n",
      "\t\t('float', [])     : 75 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', [])       :  3 | ['AST', 'ALT', 'GGT']\n",
      "\t\t('int', ['bool']) :  2 | ['H6N4F1S1', 'H6N6']\n",
      "\t0.1s = Fit runtime\n",
      "\t81 features in original data used to generate 81 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 86.93s of the 86.92s of remaining time.\n",
      "\t0.8466\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 86.30s of the 86.30s of remaining time.\n",
      "\t0.8731\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 86.29s of the 86.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t0.9027\t = Validation score   (roc_auc)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 83.96s of the 83.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\t0.9098\t = Validation score   (roc_auc)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 81.23s of the 81.23s of remaining time.\n",
      "\t0.899\t = Validation score   (roc_auc)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 80.84s of the 80.83s of remaining time.\n",
      "\t0.9008\t = Validation score   (roc_auc)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 80.51s of the 80.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\t0.9069\t = Validation score   (roc_auc)\n",
      "\t9.87s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 68.43s of the 68.43s of remaining time.\n",
      "\t0.8834\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 68.20s of the 68.20s of remaining time.\n",
      "\t0.8823\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 67.99s of the 67.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8682\t = Validation score   (roc_auc)\n",
      "\t2.21s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 64.15s of the 64.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
      "\t0.9101\t = Validation score   (roc_auc)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 60.47s of the 60.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8487\t = Validation score   (roc_auc)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 55.89s of the 55.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.37%)\n",
      "\t0.9014\t = Validation score   (roc_auc)\n",
      "\t3.93s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 50.03s of the 50.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.71%)\n",
      "\t0.9007\t = Validation score   (roc_auc)\n",
      "\t10.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 37.54s of the 37.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8744\t = Validation score   (roc_auc)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 33.48s of the 33.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.64%)\n",
      "\t0.9143\t = Validation score   (roc_auc)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 29.47s of the 29.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8654\t = Validation score   (roc_auc)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 25.10s of the 25.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.97%)\n",
      "\t0.9077\t = Validation score   (roc_auc)\n",
      "\t20.25s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2.57s of the 2.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.901\t = Validation score   (roc_auc)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 86.93s of the -1.10s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r131_BAG_L1': 0.333, 'KNeighborsDist_BAG_L1': 0.25, 'NeuralNetFastAI_BAG_L1': 0.167, 'NeuralNetTorch_r79_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.083}\n",
      "\t0.9264\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 88.18s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 189.8 rows/s (63 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065008\")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:52:12.196539Z",
     "start_time": "2024-12-03T06:52:11.545960Z"
    }
   },
   "cell_type": "code",
   "source": "predictor.evaluate(test_data)",
   "id": "387b940f9893b9dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9562920678197153,\n",
       " 'accuracy': 0.8899082568807339,\n",
       " 'balanced_accuracy': 0.8824231064156087,\n",
       " 'mcc': 0.7793228131593767,\n",
       " 'f1': 0.8681318681318682,\n",
       " 'precision': 0.9294117647058824,\n",
       " 'recall': 0.8144329896907216}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:52:17.950038Z",
     "start_time": "2024-12-03T06:52:17.947985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clinical_features = ['AST', 'ALT', 'GGT', 'ALB','TBIL', 'TP', 'AFP', 'child_pugh', 'AAR', 'ALBI_score']\n",
    "glycan_features = [col for col in train_df.columns if col not in clinical_features]\n",
    "glycan_features.remove('group')"
   ],
   "id": "658d57edc9d08777",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:30:10.654296Z",
     "start_time": "2024-12-03T06:28:08.662301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use only clinical features\n",
    "clinical_train_data = train_data[['group'] + clinical_features]\n",
    "clinical_test_data = test_data[['group'] + clinical_features]\n",
    "\n",
    "clinical_predictor = TabularPredictor('group', eval_metric='roc_auc').fit(clinical_train_data, time_limit=120, presets='best_quality')\n",
    "clinical_predictor.evaluate(clinical_test_data)"
   ],
   "id": "1f78d0ffd181751",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_062808\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.80 GB / 16.00 GB (36.2%)\n",
      "Disk Space Avail:   27.92 GB / 460.43 GB (6.1%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_062808/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBM_BAG_L2       0.895484   0.920576     roc_auc        0.479255       0.223379   9.001892                 0.007769                0.011869           0.393765            2       True         15\n",
      "1         LightGBMXT_BAG_L2       0.887742   0.928930     roc_auc        0.481154       0.224074   9.010828                 0.009668                0.012564           0.402701            2       True         14\n",
      "2   RandomForestEntr_BAG_L2       0.885161   0.913858     roc_auc        0.486002       0.243747   8.822354                 0.014515                0.032237           0.214227            2       True         17\n",
      "3           CatBoost_BAG_L2       0.882581   0.923354     roc_auc        0.476706       0.224940  12.537146                 0.005220                0.013430           3.929019            2       True         18\n",
      "4       WeightedEnsemble_L3       0.880000   0.932984     roc_auc        0.487033       0.237668  12.953693                 0.000659                0.000164           0.013846            3       True         19\n",
      "5   RandomForestGini_BAG_L2       0.878065   0.907397     roc_auc        0.486169       0.258127   8.984508                 0.014683                0.046618           0.376381            2       True         16\n",
      "6           LightGBM_BAG_L1       0.874839   0.909805     roc_auc        0.009087       0.011000   0.301025                 0.009087                0.011000           0.301025            1       True          4\n",
      "7            XGBoost_BAG_L1       0.874839   0.914126     roc_auc        0.019920       0.019922   0.363409                 0.019920                0.019922           0.363409            1       True         11\n",
      "8       WeightedEnsemble_L2       0.868387   0.927860     roc_auc        0.068874       0.099480   0.762922                 0.000678                0.000168           0.013992            2       True         13\n",
      "9   RandomForestGini_BAG_L1       0.861935   0.920525     roc_auc        0.017244       0.034818   0.306837                 0.017244                0.034818           0.306837            1       True          5\n",
      "10  RandomForestEntr_BAG_L1       0.860645   0.921584     roc_auc        0.019259       0.034065   0.218793                 0.019259                0.034065           0.218793            1       True          6\n",
      "11    ExtraTreesEntr_BAG_L1       0.856129   0.916770     roc_auc        0.017286       0.034222   0.165658                 0.017286                0.034222           0.165658            1       True          9\n",
      "12    ExtraTreesGini_BAG_L1       0.854839   0.915031     roc_auc        0.018593       0.034271   0.166339                 0.018593                0.034271           0.166339            1       True          8\n",
      "13        LightGBMXT_BAG_L1       0.854194   0.907335     roc_auc        0.091497       0.030911   0.392565                 0.091497                0.030911           0.392565            1       True          3\n",
      "14          CatBoost_BAG_L1       0.851613   0.912274     roc_auc        0.210519       0.010937   2.086927                 0.210519                0.010937           2.086927            1       True          7\n",
      "15    NeuralNetTorch_BAG_L1       0.816774   0.878899     roc_auc        0.028308       0.047536   3.709655                 0.028308                0.047536           3.709655            1       True         12\n",
      "16   NeuralNetFastAI_BAG_L1       0.811613   0.865792     roc_auc        0.155376       0.042724   1.761590                 0.155376                0.042724           1.761590            1       True         10\n",
      "17    KNeighborsDist_BAG_L1       0.762581   0.883025     roc_auc        0.011731       0.011104   0.001070                 0.011731                0.011104           0.001070            1       True          2\n",
      "18    KNeighborsUnif_BAG_L1       0.737419   0.846296     roc_auc        0.011900       0.024145   0.001647                 0.011900                0.024145           0.001647            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t32s\t = DyStack   runtime |\t88s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 88s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_062808\"\n",
      "Train Data Rows:    499\n",
      "Train Data Columns: 10\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6487.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['ALB', 'TBIL', 'TP', 'AFP', 'AAR', ...]\n",
      "\t\t('int', [])    : 3 | ['AST', 'ALT', 'GGT']\n",
      "\t\t('object', []) : 1 | ['child_pugh']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['child_pugh']\n",
      "\t\t('float', [])    : 6 | ['ALB', 'TBIL', 'TP', 'AFP', 'AAR', ...]\n",
      "\t\t('int', [])      : 3 | ['AST', 'ALT', 'GGT']\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 58.57s of the 87.87s of remaining time.\n",
      "\t0.8346\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 58.55s of the 87.85s of remaining time.\n",
      "\t0.875\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 58.53s of the 87.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9023\t = Validation score   (roc_auc)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 56.43s of the 85.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9148\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 53.87s of the 83.18s of remaining time.\n",
      "\t0.9213\t = Validation score   (roc_auc)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 53.43s of the 82.73s of remaining time.\n",
      "\t0.9258\t = Validation score   (roc_auc)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 53.17s of the 82.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8974\t = Validation score   (roc_auc)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 49.61s of the 78.92s of remaining time.\n",
      "\t0.9148\t = Validation score   (roc_auc)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 49.27s of the 78.57s of remaining time.\n",
      "\t0.915\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 49.05s of the 78.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.8509\t = Validation score   (roc_auc)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 45.62s of the 74.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "\t0.9088\t = Validation score   (roc_auc)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 42.66s of the 71.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.8528\t = Validation score   (roc_auc)\n",
      "\t3.87s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 36.84s of the 66.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
      "\t0.8915\t = Validation score   (roc_auc)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 34.42s of the 63.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t0.9097\t = Validation score   (roc_auc)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 30.94s of the 60.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.8944\t = Validation score   (roc_auc)\n",
      "\t5.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 23.90s of the 53.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t0.9071\t = Validation score   (roc_auc)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 21.56s of the 50.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.8694\t = Validation score   (roc_auc)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 16.70s of the 46.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
      "\t0.9145\t = Validation score   (roc_auc)\n",
      "\t4.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 10.34s of the 39.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8936\t = Validation score   (roc_auc)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 7.59s of the 36.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t0.8733\t = Validation score   (roc_auc)\n",
      "\t6.75s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 87.88s of the 28.41s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L1': 0.417, 'NeuralNetTorch_r79_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.125, 'LightGBM_BAG_L1': 0.083, 'ExtraTreesEntr_BAG_L1': 0.083, 'NeuralNetFastAI_r191_BAG_L1': 0.083, 'KNeighborsDist_BAG_L1': 0.042}\n",
      "\t0.9328\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 28.39s of the 28.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t0.9232\t = Validation score   (roc_auc)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 26.01s of the 25.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
      "\t0.9122\t = Validation score   (roc_auc)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 23.11s of the 23.07s of remaining time.\n",
      "\t0.9195\t = Validation score   (roc_auc)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 22.79s of the 22.76s of remaining time.\n",
      "\t0.9223\t = Validation score   (roc_auc)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 22.48s of the 22.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
      "\t0.9242\t = Validation score   (roc_auc)\n",
      "\t2.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 18.07s of the 18.03s of remaining time.\n",
      "\t0.9249\t = Validation score   (roc_auc)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 17.76s of the 17.72s of remaining time.\n",
      "\t0.9213\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 17.54s of the 17.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.9219\t = Validation score   (roc_auc)\n",
      "\t2.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 13.90s of the 13.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.25%)\n",
      "\t0.913\t = Validation score   (roc_auc)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 10.64s of the 10.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t0.9131\t = Validation score   (roc_auc)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6.37s of the 6.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.48%)\n",
      "\t0.907\t = Validation score   (roc_auc)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 2.52s of the 2.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.9273\t = Validation score   (roc_auc)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 87.88s of the -1.51s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.4, 'RandomForestEntr_BAG_L1': 0.32, 'ExtraTreesGini_BAG_L2': 0.24, 'NeuralNetTorch_BAG_L2': 0.04}\n",
      "\t0.9301\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 89.45s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 410.6 rows/s (63 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_062808\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9520320354434694,\n",
       " 'accuracy': 0.8990825688073395,\n",
       " 'balanced_accuracy': 0.8957996080770214,\n",
       " 'mcc': 0.7954033705719252,\n",
       " 'f1': 0.8842105263157894,\n",
       " 'precision': 0.9032258064516129,\n",
       " 'recall': 0.865979381443299}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:32:25.531340Z",
     "start_time": "2024-12-03T06:30:25.926273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use only glycans\n",
    "glycan_train_data = train_data[['group'] + glycan_features]\n",
    "glycan_test_data = test_data[['group'] + glycan_features]\n",
    "\n",
    "glycan_predictor = TabularPredictor('group', eval_metric='roc_auc').fit(glycan_train_data, time_limit=120, presets='best_quality')\n",
    "glycan_predictor.evaluate(glycan_test_data)"
   ],
   "id": "9cb2d6d60785bbde",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_063025\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.87 GB / 16.00 GB (36.7%)\n",
      "Disk Space Avail:   27.81 GB / 460.43 GB (6.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_063025/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           LightGBM_BAG_L1       0.860645   0.810905     roc_auc        0.021498       0.006778   0.685579                 0.021498                0.006778           0.685579            1       True          4\n",
      "1   RandomForestEntr_BAG_L1       0.835484   0.829887     roc_auc        0.036063       0.035502   0.191452                 0.036063                0.035502           0.191452            1       True          6\n",
      "2   RandomForestGini_BAG_L1       0.831613   0.834053     roc_auc        0.035826       0.042817   0.334944                 0.035826                0.042817           0.334944            1       True          5\n",
      "3         LightGBMXT_BAG_L1       0.830968   0.830412     roc_auc        0.166991       0.007532   0.486196                 0.166991                0.007532           0.486196            1       True          3\n",
      "4           CatBoost_BAG_L1       0.829677   0.840185     roc_auc        0.270134       0.016272   5.909403                 0.270134                0.016272           5.909403            1       True          7\n",
      "5            XGBoost_BAG_L1       0.824516   0.790720     roc_auc        0.016374       0.011767   1.011393                 0.016374                0.011767           1.011393            1       True         11\n",
      "6   RandomForestEntr_BAG_L2       0.821290   0.824249     roc_auc        0.703584       0.225642  10.024118                 0.015831                0.039031           0.237072            2       True         16\n",
      "7       WeightedEnsemble_L2       0.816774   0.850967     roc_auc        0.654438       0.140962   8.624129                 0.000744                0.000272           0.015244            2       True         12\n",
      "8     ExtraTreesEntr_BAG_L1       0.805806   0.830751     roc_auc        0.017687       0.034155   0.166769                 0.017687                0.034155           0.166769            1       True          9\n",
      "9       WeightedEnsemble_L3       0.803871   0.853724     roc_auc        0.694674       0.197568  10.399242                 0.000622                0.000292           0.015586            3       True         18\n",
      "10    ExtraTreesGini_BAG_L1       0.800000   0.830288     roc_auc        0.019627       0.041028   0.391383                 0.019627                0.041028           0.391383            1       True          8\n",
      "11          CatBoost_BAG_L2       0.796129   0.837901     roc_auc        0.695688       0.217198  12.298136                 0.007934                0.030586           2.511089            2       True         17\n",
      "12  RandomForestGini_BAG_L2       0.793548   0.825072     roc_auc        0.705191       0.230777  10.116875                 0.017437                0.044166           0.329829            2       True         15\n",
      "13          LightGBM_BAG_L2       0.785806   0.838498     roc_auc        0.693256       0.197164  10.797141                 0.005502                0.010552           1.010095            2       True         14\n",
      "14        LightGBMXT_BAG_L2       0.784516   0.840535     roc_auc        0.694052       0.197276  10.383656                 0.006298                0.010665           0.596610            2       True         13\n",
      "15   NeuralNetFastAI_BAG_L1       0.766452   0.813663     roc_auc        0.176821       0.072676   1.876085                 0.176821                0.072676           1.876085            1       True         10\n",
      "16    KNeighborsUnif_BAG_L1       0.685161   0.771049     roc_auc        0.003899       0.014751   0.002739                 0.003899                0.014751           0.002739            1       True          1\n",
      "17    KNeighborsDist_BAG_L1       0.685161   0.782305     roc_auc        0.003921       0.001393   0.002256                 0.003921                0.001393           0.002256            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t33s\t = DyStack   runtime |\t87s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 87s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_063025\"\n",
      "Train Data Rows:    499\n",
      "Train Data Columns: 72\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6612.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['H3N2F1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 71 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 69 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['H6N4F1S1', 'H6N6']\n",
      "\t0.0s = Fit runtime\n",
      "\t71 features in original data used to generate 71 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 86.94s of the 86.94s of remaining time.\n",
      "\t0.7553\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 86.92s of the 86.92s of remaining time.\n",
      "\t0.7679\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 86.91s of the 86.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.22%)\n",
      "\t0.8432\t = Validation score   (roc_auc)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.31s of the 84.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
      "\t0.8329\t = Validation score   (roc_auc)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 81.50s of the 81.50s of remaining time.\n",
      "\t0.8284\t = Validation score   (roc_auc)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 81.04s of the 81.04s of remaining time.\n",
      "\t0.8362\t = Validation score   (roc_auc)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 80.80s of the 80.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.41%)\n",
      "\t0.8317\t = Validation score   (roc_auc)\n",
      "\t7.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 72.07s of the 72.07s of remaining time.\n",
      "\t0.834\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 71.84s of the 71.83s of remaining time.\n",
      "\t0.836\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 71.62s of the 71.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8289\t = Validation score   (roc_auc)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 67.78s of the 67.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.61%)\n",
      "\t0.8201\t = Validation score   (roc_auc)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 63.99s of the 63.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8178\t = Validation score   (roc_auc)\n",
      "\t3.29s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 58.61s of the 58.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.95%)\n",
      "\t0.8055\t = Validation score   (roc_auc)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 53.62s of the 53.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.54%)\n",
      "\t0.8323\t = Validation score   (roc_auc)\n",
      "\t6.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 44.83s of the 44.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.8455\t = Validation score   (roc_auc)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 40.67s of the 40.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8351\t = Validation score   (roc_auc)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 36.73s of the 36.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t0.8173\t = Validation score   (roc_auc)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 32.26s of the 32.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.27%)\n",
      "\t0.8362\t = Validation score   (roc_auc)\n",
      "\t26.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 3.58s of the 3.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
      "\t0.8428\t = Validation score   (roc_auc)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 86.94s of the 0.74s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.3, 'NeuralNetTorch_r79_BAG_L1': 0.3, 'NeuralNetFastAI_BAG_L1': 0.2, 'KNeighborsDist_BAG_L1': 0.1, 'CatBoost_r9_BAG_L1': 0.1}\n",
      "\t0.8623\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 86.29s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 295.8 rows/s (63 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_063025\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.880122688932436,\n",
       " 'accuracy': 0.7706422018348624,\n",
       " 'balanced_accuracy': 0.7657834199539917,\n",
       " 'mcc': 0.5341213678827081,\n",
       " 'f1': 0.7368421052631579,\n",
       " 'precision': 0.7526881720430108,\n",
       " 'recall': 0.7216494845360825}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:56:49.018971Z",
     "start_time": "2024-12-03T06:54:47.937183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train three models to predict HCC vs HC, HCC vs CHB, HCC vs LC\n",
    "# using only glycans.\n",
    "\n",
    "HCC_HC_train_df = train_df[np.isin(train_df.group, ['HCC', 'HC'])]\n",
    "HCC_HC_test_df = test_df[np.isin(test_df.group, ['HCC', 'HC'])]\n",
    "HCC_HC_train_data = TabularDataset(HCC_HC_train_df)\n",
    "HCC_HC_test_data = TabularDataset(HCC_HC_test_df)\n",
    "HCC_HC_train_data['group'] = HCC_HC_train_data['group'] == 'HCC'\n",
    "HCC_HC_test_data['group'] = HCC_HC_test_data['group'] == 'HCC'\n",
    "HCC_HC_train_data = HCC_HC_train_data[['group'] + glycan_features]\n",
    "HCC_HC_test_data = HCC_HC_test_data[['group'] + glycan_features]\n",
    "\n",
    "HCC_HC_predictor = TabularPredictor('group', eval_metric='roc_auc').fit(HCC_HC_train_data, time_limit=120, presets='best_quality')\n",
    "HCC_HC_predictor.evaluate(HCC_HC_test_data)"
   ],
   "id": "ef0b6afc786ea3a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_065447\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.19 GB / 16.00 GB (32.5%)\n",
      "Disk Space Avail:   31.30 GB / 460.43 GB (6.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065447/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTreesEntr_BAG_L1          0.975   0.940121     roc_auc        0.035055       0.031311   0.176584                 0.035055                0.031311           0.176584            1       True          9\n",
      "1     ExtraTreesGini_BAG_L1          0.965   0.948548     roc_auc        0.028908       0.032851   0.170238                 0.028908                0.032851           0.170238            1       True          8\n",
      "2       WeightedEnsemble_L3          0.965   0.966290     roc_auc        0.128135       0.039285   0.649944                 0.000461                0.000195           0.010447            3       True         17\n",
      "3       WeightedEnsemble_L2          0.965   0.966210     roc_auc        0.128301       0.039300   0.650007                 0.000627                0.000210           0.010510            2       True         11\n",
      "4         LightGBMXT_BAG_L1          0.960   0.964032     roc_auc        0.098766       0.006239   0.469259                 0.098766                0.006239           0.469259            1       True          3\n",
      "5           CatBoost_BAG_L1          0.960   0.952419     roc_auc        0.328249       0.014259  11.640488                 0.328249                0.014259          11.640488            1       True          7\n",
      "6           LightGBM_BAG_L1          0.950   0.946613     roc_auc        0.010680       0.005861   0.456637                 0.010680                0.005861           0.456637            1       True          4\n",
      "7   RandomForestEntr_BAG_L1          0.950   0.945524     roc_auc        0.018782       0.030845   0.222597                 0.018782                0.030845           0.222597            1       True          6\n",
      "8           CatBoost_BAG_L2          0.950   0.945887     roc_auc        0.682947       0.195817  16.287825                 0.007267                0.029985           1.496423            2       True         16\n",
      "9         LightGBMXT_BAG_L2          0.945   0.958952     roc_auc        0.682161       0.177681  15.183397                 0.006480                0.011850           0.391995            2       True         12\n",
      "10  RandomForestEntr_BAG_L2          0.945   0.946250     roc_auc        0.692235       0.196680  15.010866                 0.016555                0.030848           0.219464            2       True         15\n",
      "11  RandomForestGini_BAG_L1          0.940   0.935806     roc_auc        0.018762       0.037382   0.314726                 0.018762                0.037382           0.314726            1       True          5\n",
      "12          LightGBM_BAG_L2          0.940   0.946774     roc_auc        0.680511       0.173277  15.253745                 0.004831                0.007445           0.462343            2       True         13\n",
      "13  RandomForestGini_BAG_L2          0.940   0.950766     roc_auc        0.691534       0.209036  15.136059                 0.015853                0.043204           0.344657            2       True         14\n",
      "14   NeuralNetFastAI_BAG_L1          0.870   0.909597     roc_auc        0.199261       0.080406   2.286866                 0.199261                0.080406           2.286866            1       True         10\n",
      "15    KNeighborsDist_BAG_L1          0.730   0.862984     roc_auc        0.001715       0.001231   0.001954                 0.001715                0.001231           0.001954            1       True          2\n",
      "16    KNeighborsUnif_BAG_L1          0.720   0.853750     roc_auc        0.002554       0.013480   0.002420                 0.002554                0.013480           0.002420            1       True          1\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t33s\t = DyStack   runtime |\t87s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 87s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065447\"\n",
      "Train Data Rows:    295\n",
      "Train Data Columns: 72\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5904.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['H3N2F1', 'H6N6']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 70 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 69 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['H6N4F1S1']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 86.77s of the 86.77s of remaining time.\n",
      "\t0.8458\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 86.76s of the 86.75s of remaining time.\n",
      "\t0.8567\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 86.74s of the 86.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.9601\t = Validation score   (roc_auc)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.51s of the 84.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t0.9432\t = Validation score   (roc_auc)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 81.90s of the 81.89s of remaining time.\n",
      "\t0.937\t = Validation score   (roc_auc)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 81.56s of the 81.56s of remaining time.\n",
      "\t0.9386\t = Validation score   (roc_auc)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 81.32s of the 81.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
      "\t0.9507\t = Validation score   (roc_auc)\n",
      "\t33.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 46.61s of the 46.60s of remaining time.\n",
      "\t0.9446\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 46.39s of the 46.39s of remaining time.\n",
      "\t0.9494\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 46.17s of the 46.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.9088\t = Validation score   (roc_auc)\n",
      "\t2.15s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 42.63s of the 42.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.65%)\n",
      "\t0.9326\t = Validation score   (roc_auc)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 40.08s of the 40.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.9076\t = Validation score   (roc_auc)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 35.98s of the 35.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.26%)\n",
      "\t0.9177\t = Validation score   (roc_auc)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 32.36s of the 32.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.9513\t = Validation score   (roc_auc)\n",
      "\t7.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 22.93s of the 22.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.9578\t = Validation score   (roc_auc)\n",
      "\t3.11s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 18.06s of the 18.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\t0.9479\t = Validation score   (roc_auc)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 14.99s of the 14.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.9368\t = Validation score   (roc_auc)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 9.93s of the 9.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.54%)\n",
      "\t0.9394\t = Validation score   (roc_auc)\n",
      "\t8.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 86.77s of the -0.55s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.421, 'NeuralNetTorch_r79_BAG_L1': 0.263, 'NeuralNetFastAI_r191_BAG_L1': 0.158, 'KNeighborsDist_BAG_L1': 0.053, 'ExtraTreesEntr_BAG_L1': 0.053, 'CatBoost_r177_BAG_L1': 0.053}\n",
      "\t0.9667\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 87.41s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 140.1 rows/s (37 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065447\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9527768540073163,\n",
       " 'accuracy': 0.921875,\n",
       " 'balanced_accuracy': 0.8935816428333887,\n",
       " 'mcc': 0.7871632856667775,\n",
       " 'f1': 0.9484536082474226,\n",
       " 'precision': 0.9484536082474226,\n",
       " 'recall': 0.9484536082474226}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:59:47.114536Z",
     "start_time": "2024-12-03T06:57:46.745605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train three models to predict HCC vs HC, HCC vs CHB, HCC vs LC\n",
    "# using only glycans.\n",
    "\n",
    "HCC_CHB_train_df = train_df[np.isin(train_df.group, ['HCC', 'CHB'])]\n",
    "HCC_CHB_test_df = test_df[np.isin(test_df.group, ['HCC', 'CHB'])]\n",
    "HCC_CHB_train_data = TabularDataset(HCC_CHB_train_df)\n",
    "HCC_CHB_test_data = TabularDataset(HCC_CHB_test_df)\n",
    "HCC_CHB_train_data['group'] = HCC_CHB_train_data['group'] == 'HCC'\n",
    "HCC_CHB_test_data['group'] = HCC_CHB_test_data['group'] == 'HCC'\n",
    "HCC_CHB_train_data = HCC_CHB_train_data[['group'] + glycan_features]\n",
    "HCC_CHB_test_data = HCC_CHB_test_data[['group'] + glycan_features]\n",
    "\n",
    "HCC_CHB_predictor = TabularPredictor('group', eval_metric='roc_auc').fit(HCC_CHB_train_data, time_limit=120, presets='best_quality')\n",
    "HCC_CHB_predictor.evaluate(HCC_CHB_test_data)"
   ],
   "id": "9729be70db37d1ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_065746\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.08 GB / 16.00 GB (31.7%)\n",
      "Disk Space Avail:   31.21 GB / 460.43 GB (6.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065746/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2       0.840000   0.921667     roc_auc        0.693768       0.144062   9.938065                 0.000856                0.000213           0.012477            2       True         12\n",
      "1         LightGBMXT_BAG_L1       0.836667   0.907389     roc_auc        0.110971       0.006181   0.446317                 0.110971                0.006181           0.446317            1       True          3\n",
      "2           LightGBM_BAG_L2       0.826667   0.893667     roc_auc        0.713421       0.177971  10.972541                 0.004474                0.020754           0.468262            2       True         14\n",
      "3       WeightedEnsemble_L3       0.826667   0.922222     roc_auc        0.716714       0.178101  13.846582                 0.000775                0.000282           0.012748            3       True         18\n",
      "4           CatBoost_BAG_L2       0.823333   0.904389     roc_auc        0.715939       0.177819  13.833834                 0.006991                0.020603           3.329555            2       True         17\n",
      "5           CatBoost_BAG_L1       0.820000   0.898111     roc_auc        0.350145       0.009337   6.696482                 0.350145                0.009337           6.696482            1       True          7\n",
      "6         LightGBMXT_BAG_L2       0.820000   0.902444     roc_auc        0.714015       0.169604  10.972114                 0.005067                0.012388           0.467835            2       True         13\n",
      "7     ExtraTreesEntr_BAG_L1       0.816667   0.888583     roc_auc        0.020192       0.032136   0.169729                 0.020192                0.032136           0.169729            1       True          9\n",
      "8   RandomForestGini_BAG_L1       0.816667   0.881278     roc_auc        0.020726       0.042954   0.399570                 0.020726                0.042954           0.399570            1       True          5\n",
      "9   RandomForestEntr_BAG_L1       0.813333   0.886861     roc_auc        0.020854       0.031673   0.179834                 0.020854                0.031673           0.179834            1       True          6\n",
      "10  RandomForestEntr_BAG_L2       0.810000   0.887417     roc_auc        0.722883       0.190123  10.713464                 0.013935                0.032906           0.209185            2       True         16\n",
      "11    ExtraTreesGini_BAG_L1       0.805000   0.879778     roc_auc        0.031970       0.032360   0.170283                 0.031970                0.032360           0.170283            1       True          8\n",
      "12           XGBoost_BAG_L1       0.800000   0.877528     roc_auc        0.016036       0.013368   0.578691                 0.016036                0.013368           0.578691            1       True         11\n",
      "13  RandomForestGini_BAG_L2       0.791667   0.883083     roc_auc        0.726366       0.203484  10.858918                 0.017418                0.046267           0.354639            2       True         15\n",
      "14    KNeighborsDist_BAG_L1       0.790000   0.832194     roc_auc        0.002191       0.001099   0.001956                 0.002191                0.001099           0.001956            1       True          2\n",
      "15          LightGBM_BAG_L1       0.790000   0.888667     roc_auc        0.007687       0.004768   0.429800                 0.007687                0.004768           0.429800            1       True          4\n",
      "16   NeuralNetFastAI_BAG_L1       0.783333   0.892944     roc_auc        0.188559       0.063423   2.431270                 0.188559                0.063423           2.431270            1       True         10\n",
      "17    KNeighborsUnif_BAG_L1       0.775000   0.826028     roc_auc        0.003416       0.014721   0.002569                 0.003416                0.014721           0.002569            1       True          1\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t33s\t = DyStack   runtime |\t87s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 87s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065746\"\n",
      "Train Data Rows:    327\n",
      "Train Data Columns: 72\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6073.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['H3N2F1', 'H4N4F3S1', 'H6N6']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 69 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 68 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['H6N4F1S1']\n",
      "\t0.0s = Fit runtime\n",
      "\t69 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 87.11s of the 87.11s of remaining time.\n",
      "\t0.8161\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 87.10s of the 87.09s of remaining time.\n",
      "\t0.8259\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 87.08s of the 87.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
      "\t0.8871\t = Validation score   (roc_auc)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.58s of the 84.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.27%)\n",
      "\t0.8713\t = Validation score   (roc_auc)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 80.99s of the 80.99s of remaining time.\n",
      "\t0.8685\t = Validation score   (roc_auc)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 80.61s of the 80.61s of remaining time.\n",
      "\t0.8672\t = Validation score   (roc_auc)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 80.32s of the 80.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.51%)\n",
      "\t0.8947\t = Validation score   (roc_auc)\n",
      "\t8.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 69.99s of the 69.99s of remaining time.\n",
      "\t0.8876\t = Validation score   (roc_auc)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 69.64s of the 69.64s of remaining time.\n",
      "\t0.8804\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 69.43s of the 69.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.8675\t = Validation score   (roc_auc)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 64.32s of the 64.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.66%)\n",
      "\t0.8668\t = Validation score   (roc_auc)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 60.27s of the 60.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8622\t = Validation score   (roc_auc)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 55.27s of the 55.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.29%)\n",
      "\t0.838\t = Validation score   (roc_auc)\n",
      "\t2.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 50.62s of the 50.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.59%)\n",
      "\t0.8956\t = Validation score   (roc_auc)\n",
      "\t7.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 41.00s of the 40.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.8622\t = Validation score   (roc_auc)\n",
      "\t4.07s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 34.74s of the 34.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.52%)\n",
      "\t0.8773\t = Validation score   (roc_auc)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 30.56s of the 30.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.867\t = Validation score   (roc_auc)\n",
      "\t4.43s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 23.20s of the 23.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.46%)\n",
      "\t0.8814\t = Validation score   (roc_auc)\n",
      "\t18.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 87.11s of the 0.12s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 0.571, 'ExtraTreesGini_BAG_L1': 0.143, 'NeuralNetFastAI_BAG_L1': 0.143, 'NeuralNetTorch_r79_BAG_L1': 0.143}\n",
      "\t0.9045\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 87.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 136.5 rows/s (41 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_065746\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.9040091638029782,\n",
       " 'accuracy': 0.8169014084507042,\n",
       " 'balanced_accuracy': 0.7766323024054982,\n",
       " 'mcc': 0.5680314683204689,\n",
       " 'f1': 0.8686868686868687,\n",
       " 'precision': 0.8514851485148515,\n",
       " 'recall': 0.8865979381443299}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:02:18.990211Z",
     "start_time": "2024-12-03T07:00:19.055705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train three models to predict HCC vs HC, HCC vs CHB, HCC vs LC\n",
    "# using only glycans.\n",
    "\n",
    "HCC_LC_train_df = train_df[np.isin(train_df.group, ['HCC', 'LC'])]\n",
    "HCC_LC_test_df = test_df[np.isin(test_df.group, ['HCC', 'LC'])]\n",
    "HCC_LC_train_data = TabularDataset(HCC_LC_train_df)\n",
    "HCC_LC_test_data = TabularDataset(HCC_LC_test_df)\n",
    "HCC_LC_train_data['group'] = HCC_LC_train_data['group'] == 'HCC'\n",
    "HCC_LC_test_data['group'] = HCC_LC_test_data['group'] == 'HCC'\n",
    "HCC_LC_train_data = HCC_LC_train_data[['group'] + glycan_features]\n",
    "HCC_LC_test_data = HCC_LC_test_data[['group'] + glycan_features]\n",
    "\n",
    "HCC_LC_predictor = TabularPredictor('group', eval_metric='roc_auc').fit(HCC_LC_train_data, time_limit=120, presets='best_quality')\n",
    "HCC_LC_predictor.evaluate(HCC_LC_test_data)"
   ],
   "id": "d7c4f94b723cfc17",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_070019\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:02:26 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.01 GB / 16.00 GB (31.3%)\n",
      "Disk Space Avail:   31.15 GB / 460.43 GB (6.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_070019/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1       0.763333   0.727500     roc_auc        0.400731       0.013038   7.317175                 0.400731                0.013038           7.317175            1       True          7\n",
      "1   RandomForestGini_BAG_L2       0.761667   0.730111     roc_auc        0.846200       0.211833  11.395568                 0.017730                0.042711           0.394823            2       True         14\n",
      "2   RandomForestGini_BAG_L1       0.760000   0.735472     roc_auc        0.032343       0.048415   0.337753                 0.032343                0.048415           0.337753            1       True          5\n",
      "3           CatBoost_BAG_L2       0.760000   0.767556     roc_auc        0.835649       0.192105  13.014337                 0.007180                0.022983           2.013592            2       True         16\n",
      "4           LightGBM_BAG_L1       0.756667   0.718028     roc_auc        0.008013       0.007636   0.701060                 0.008013                0.007636           0.701060            1       True          4\n",
      "5         LightGBMXT_BAG_L1       0.756667   0.747111     roc_auc        0.196636       0.004610   0.424908                 0.196636                0.004610           0.424908            1       True          3\n",
      "6       WeightedEnsemble_L2       0.723333   0.780056     roc_auc        0.407376       0.120455   3.420576                 0.000686                0.000256           0.017879            2       True         11\n",
      "7   RandomForestEntr_BAG_L1       0.720000   0.742528     roc_auc        0.021049       0.035885   0.280873                 0.021049                0.035885           0.280873            1       True          6\n",
      "8     KNeighborsDist_BAG_L1       0.706667   0.695389     roc_auc        0.003074       0.001177   0.001924                 0.003074                0.001177           0.001924            1       True          2\n",
      "9     KNeighborsUnif_BAG_L1       0.706667   0.686833     roc_auc        0.003951       0.013888   0.002412                 0.003951                0.013888           0.002412            1       True          1\n",
      "10  RandomForestEntr_BAG_L2       0.705000   0.732306     roc_auc        0.843022       0.203016  11.299837                 0.014553                0.033894           0.299092            2       True         15\n",
      "11      WeightedEnsemble_L3       0.700000   0.789222     roc_auc        0.843048       0.203557  13.582693                 0.000732                0.000243           0.011287            3       True         17\n",
      "12    ExtraTreesEntr_BAG_L1       0.695000   0.751417     roc_auc        0.018763       0.031886   0.170585                 0.018763                0.031886           0.170585            1       True          9\n",
      "13        LightGBMXT_BAG_L2       0.690000   0.763889     roc_auc        0.835135       0.180330  11.557814                 0.006666                0.011208           0.557069            2       True         12\n",
      "14          LightGBM_BAG_L2       0.690000   0.728667     roc_auc        0.832806       0.181658  11.614234                 0.004337                0.012536           0.613489            2       True         13\n",
      "15    ExtraTreesGini_BAG_L1       0.678333   0.737722     roc_auc        0.019284       0.032654   0.167234                 0.019284                0.032654           0.167234            1       True          8\n",
      "16   NeuralNetFastAI_BAG_L1       0.626667   0.742667     roc_auc        0.188216       0.082526   2.805280                 0.188216                0.082526           2.805280            1       True         10\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t34s\t = DyStack   runtime |\t86s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 86s\n",
      "AutoGluon will save models to \"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_070019\"\n",
      "Train Data Rows:    327\n",
      "Train Data Columns: 72\n",
      "Label Column:       group\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5853.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['H3N2F1', 'H4N4F3S1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 70 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 68 | ['H3N3', 'H3N3F1', 'H3N4', 'H3N4F1', 'H3N5', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['H6N4F1S1', 'H6N6']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 86.01s of the 86.00s of remaining time.\n",
      "\t0.6659\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 85.99s of the 85.99s of remaining time.\n",
      "\t0.6896\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 85.98s of the 85.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.24%)\n",
      "\t0.7688\t = Validation score   (roc_auc)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 83.31s of the 83.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
      "\t0.7211\t = Validation score   (roc_auc)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 80.48s of the 80.48s of remaining time.\n",
      "\t0.7487\t = Validation score   (roc_auc)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 80.21s of the 80.20s of remaining time.\n",
      "\t0.7442\t = Validation score   (roc_auc)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 79.64s of the 79.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
      "\t0.7734\t = Validation score   (roc_auc)\n",
      "\t8.56s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 69.22s of the 69.21s of remaining time.\n",
      "\t0.7452\t = Validation score   (roc_auc)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 69.00s of the 68.99s of remaining time.\n",
      "\t0.7508\t = Validation score   (roc_auc)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 68.77s of the 68.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t0.7308\t = Validation score   (roc_auc)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 64.12s of the 64.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.65%)\n",
      "\t0.7129\t = Validation score   (roc_auc)\n",
      "\t1.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 59.71s of the 59.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.7481\t = Validation score   (roc_auc)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 54.04s of the 54.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.26%)\n",
      "\t0.6986\t = Validation score   (roc_auc)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 48.75s of the 48.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\t0.7543\t = Validation score   (roc_auc)\n",
      "\t8.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 37.57s of the 37.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t0.7634\t = Validation score   (roc_auc)\n",
      "\t4.34s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 30.73s of the 30.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.43%)\n",
      "\t0.7237\t = Validation score   (roc_auc)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 27.11s of the 27.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t0.7238\t = Validation score   (roc_auc)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 20.93s of the 20.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.51%)\n",
      "\t0.7541\t = Validation score   (roc_auc)\n",
      "\t17.14s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 86.01s of the 0.47s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.44, 'NeuralNetTorch_r79_BAG_L1': 0.2, 'KNeighborsDist_BAG_L1': 0.16, 'CatBoost_BAG_L1': 0.12, 'NeuralNetFastAI_BAG_L1': 0.08}\n",
      "\t0.802\t = Validation score   (roc_auc)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 85.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 125.0 rows/s (41 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/fubin/科研/HCC-N-glycome/src/ml/AutogluonModels/ag-20241203_070019\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8258877434135166,\n",
       " 'accuracy': 0.7746478873239436,\n",
       " 'balanced_accuracy': 0.668270332187858,\n",
       " 'mcc': 0.4410901292841179,\n",
       " 'f1': 0.8532110091743119,\n",
       " 'precision': 0.768595041322314,\n",
       " 'recall': 0.9587628865979382}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2cf22151652eebb7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
